---
title: "November"
---

**Portkey in November**

A landmark month at Portkey! We won the NetApp Excellerator Award, launched prompt.new for faster development, added folder organization and AI suggestions for prompts, and introduced multi-workspace analytics. Plus, there's now support for OpenAI's Realtime API and much more. Let's dive in!

### Executive Summary
| | |
| :-- | :-- |
| Platform Growth | ‚Ä¢ Won the Best Growth Strategy Award at NetApp's Excellerator for our open-source AI Gateway<br/>‚Ä¢ Featured testimonial from Premera Blue Cross's Director of Platform Engineering<br/>‚Ä¢ Launched weekly AI Engineering Office Hours for the community<br/>‚Ä¢ Over 6,000 GitHub stars and growing |
| Developer Experience | ‚Ä¢ Introduced [prompt.new](https://prompt.new) for instant prompt creation<br/>‚Ä¢ Added prompt folders and AI suggestions for template creation<br/>‚Ä¢ Enhanced analytics with request/response token breakdowns<br/>‚Ä¢ New onboarding flow and login experience<br/>‚Ä¢ Added version tags for prompts |
| Enterprise Features | ‚Ä¢ Multi-workspace analytics for centralized admin control<br/>‚Ä¢ Enterprise authentication with AWS STS and Azure Entra<br/>‚Ä¢ Dynamic usage limits and API key management<br/>‚Ä¢ New security settings in admin dashboard<br/>‚Ä¢ Support for any S3-compatible store |
| Integrations & SDKs | ‚Ä¢ Added support for OpenAI & Azure OpenAI Realtime API<br/>‚Ä¢ AWS Sagemaker integration for model hosting<br/>‚Ä¢ New models from xAI, Llama 3.3, and Gemini 2.0 Flash<br/>‚Ä¢ Enhanced Python SDK with streaming for assistants<br/>‚Ä¢ Added Semantic Kernel support for .NET |
| OpenAI Swarm | ‚Ä¢ Complete observability with cost tracking and monitoring<br/>‚Ä¢ Built-in caching and fallbacks for reliability<br/>‚Ä¢ Interoperability with various LLM providers<br/>‚Ä¢ Security controls and budget management |
| Community Events | ‚Ä¢ Hosted successful AWS re:Invent meetup<br/>‚Ä¢ First Portkey Practitioners Dinner in Singapore<br/>‚Ä¢ Released "Lessons from Building a Billion-scale AI Gateway"<br/>‚Ä¢ Published comprehensive guides on o1 models, LLM Gateways |

### Features

#### Prompt Management
- **prompt.new**: Quick access to create new prompts. Just type prompt.new in your browser! [(*Try Now*)](https://prompt.new)
- **Prompt Folders**: Organize your prompts better with folders and subfolders
- **AI-Powered Templates**: Get AI suggestions while creating prompt templates
- **Version Tags**: Add version information to your prompts for better tracking

#### Analytics & Monitoring
- **Token Breakdown**: See the split between Request & Response tokens in analytics
- **Multi-Workspace View**: Admins can now view analytics and logs across all workspaces in one place
- **New Request Metrics**: Track throughput, total latency, and total tokens for each request in prompt playground

#### Real-time Capabilities
- **OpenAI Realtime API**: Full support for OpenAI and Azure OpenAI's Realtime API with accurate logging and cost calculations
- **Vertex AI Updates**:
  - Added Controlled Generations support
  - Better support for Gemini JSON mode
  - Enhanced Pydantic integration

#### Enterprise Security
- **Dynamic Controls**:
  - Usage and rate limits for virtual keys
  - Budget limits with periodic resets
  - Auto-expiring API keys
- **New Security Dashboard**: Enhanced security settings in admin page
- **Authentication**:
  - AWS STS with role and IMDS-based auth
  - Azure Entra (previously Active Directory) integration
  - Support for managed identities

#### Platform Improvements
- **Enhanced Onboarding**: New user onboarding flow and login experience
- **Sagemaker Integration**: Route to your models hosted on Sagemaker, use Portkey as central auth layer
- **Strict OpenAI Compliance**: New `strictOpenAiCompliance` mode for better compatibility

---

### Models & Integrations

#### New Model Support
Expanding our supported models across providers:
<CardGroup cols={2}>
<Card title="xAI">
Route and monitor all your xAI model requests through Portkey
</Card>
<Card title="Llama 3.3">
Available across multiple providers including Fireworks, AWS Bedrock, and more
</Card>
<Card title="Gemini 2.0 Flash">
Enhanced support for Google's latest Gemini model
</Card>
<Card title="o1 Models">
Full support for OpenAI's latest base models
</Card>
</CardGroup>

#### Enterprise Integrations
Production-ready integrations for enterprise deployments:
<CardGroup cols={2}>
<Card title="AWS Sagemaker" href="/integrations/llms/sagemaker">
Use Portkey as your central authentication layer for Sagemaker-hosted models
</Card>
<Card title="Ollama Tool Calling" href="/integrations/ollama">
Newly released tool calling feature for Ollama is now supported on Portkey
</Card>
</CardGroup>

#### Libraries
<CardGroup cols={2}>
<Card title="OpenAI Swarm" href="/integrations/agents/openai-swarm">
Complete observability and reliability features for Swarm agents including cost tracking, caching, and monitoring
</Card>
<Card title="Semantic Kernel" href="/docs/api-reference/inference-api/sdks/c-sharp#microsoft-semantic-kernel-example">
Build enterprise-ready .NET applications using Microsoft's Semantic Kernel
</Card>
<Card title="Supabase" href="/docs/integrations/libraries/supabase">
Seamlessly integrate LLM capabilities with your Supabase applications
</Card>
</CardGroup>

#### Guardrails

<CardGroup cols={2}>
    <Card title="Pangea Guardrails" href="/docs/product/guardrails/pangea">
    Additional security controls with Pangea integration
    </Card>
</CardGroup>

---

### Platform Updates

#### Workflow Improvements
New features to enhance your development experience:
- **Better Templates**: AI suggestions while creating prompt templates
- **Prompt Management**:
  - Organize prompts with folders
  - Add version tags to track changes
  - Quick access with prompt.new
- **Enhanced Analytics**:
  - See token split between requests & responses
  - Track throughput and latency per request
  - Filter logs & analytics by API key

#### Enterprise Controls
Enhanced security and management features:
<CardGroup cols={2}>
<Card title="Multi-Workspace Analytics">
Admins can now view and manage analytics across all workspaces from a central dashboard
</Card>
<Card title="Dynamic Key Management">
Set budget limits, rate limits, and auto-expiry for both Virtual and API keys
</Card>
</CardGroup>

#### Security Updates
New authentication and compliance features:
- **AWS Authentication**: Support for both role-based and IMDS-based authentication
- **Azure Integration**: Enhanced support for Azure Entra and managed identities
- **S3 Compatibility**: Support for any S3-compliant storage
- **New Admin Interface**: Dedicated security settings screen in admin dashboard

#### SDK Improvements
- Stream support for assistant threads and runs
- Enhanced Pydantic version support for Python
- Fixed Httpx proxy issues

---

### Resources & Community

#### Latest Guides
Essential reads for AI infrastructure:
- [Deep Dive into O1 Models](https://x.com/jumbld/status/1865998112663420934): Must-read analysis of OpenAI's latest base models
- [Build vs Buy: LLM Gateways](https://portkey.ai/blog/build-vs-buy-llm-gateways/): Make the right choice for your AI infrastructure
- [AI Gateway vs API Gateway](https://portkey.ai/blog/ai-gateway-vs-api-gateway/): Understanding key differences and capabilities
- [FinOps for GenAI](https://portkey.ai/blog/finops-to-optimize-genai-costs/): Optimize your generative AI costs

#### Technical Deep Dives
<CardGroup cols={2}>
<Card title="Billion-scale AI Gateway" href="https://www.youtube.com/watch?v=9VbjUBze9Y0">
Learn how we built and scaled Portkey's AI Gateway to process billions of requests
</Card>
<Card title="Stardog + NVIDIA Triton" href="https://portkey.ai/blog/how-stardog-uses-nvidia-triton-server-and-portkey/">
Case study on enterprise AI infrastructure deployment
</Card>
</CardGroup>

#### Community Events
<CardGroup cols={2}>
<Card title="AI Engineering Office Hours" href="/docs/changelog/office-hour">
Join us every Friday for technical discussions and live problem-solving
</Card>
<Card title="AWS re:Invent Meetup" href="https://lu.ma/jyreb3gd">
Insights from leaders at GreyOrange, Freshworks, Gracker, and Scrut Automation
</Card>
</CardGroup>

#### Industry Recognition
- üèÜ **NetApp Excellerator Award**: Won the Best Growth Strategy Award for our open-source journey
- üí° **Enterprise Success**: "Now that we've seen positive results, we're going to move all our prompts to Portkey" - [Read More](https://x.com/PortkeyAI/status/1854976581686771904)
- üöÄ **Technical Excellence**: Featured implementation of ["Chat with knowledge graph, built using Portkey"](https://x.com/PortkeyAI/status/1863450029626978707)

Check out more technical content on our [Blog ‚Üí](https://portkey.ai/blog)

---

### Fixes & Improvements

#### Model Updates
Fixed core provider issues and improved reliability:
- **Gemini**:
  - Added fallback for message index in chat completions
  - Fixed error message transformation
  - Enhanced media file handling
- **Bedrock**:
  - Fixed message concatenation issues
  - Removed additional line separators
  - Improved JSON tool handling
- **Vertex AI**: Enhanced Zod validation support

#### SDK Fixes
- Fixed semantic cache triggering for response formats
- Resolved Httpx proxy issues in Python SDK
- Enhanced error handling across SDKs

#### Additional Improvements
- Added support for additional provider headers
- Enhanced cross-region model support
- Improved token counting accuracy

---

### Support

<CardGroup cols={2}>
<Card title="Bug Report" icon="bug" href="https://github.com/Portkey-AI/gateway/issues">
Found a bug or have a feature request? Open an issue on our GitHub repository.
</Card>
<Card title="Join Portkey Discord" icon="discord" href="https://portkey.wiki/community">
Join our weekly AI Engineering Office Hours and get 24x7 support from the community.
</Card>
</CardGroup>

Thanks to all our contributors, especially [harupy](https://github.com/harupy) and [Ignacio Gleser](https://www.linkedin.com/in/ignacio-gleser-3499b33a/) for their valuable contributions this month!
