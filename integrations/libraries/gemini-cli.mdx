---
title: 'LibreChat-new'
description: 'Cost tracking, observability, and more for LibreChat'
---

Portkey **natively integrates** with LibreChat and makes your LibreChat deployments **production-grade** and **reliable** with our suite of features:

- **Unified AI Gateway** - Single interface for 1600+ LLMs with API key management. (not just OpenAI & Anthropic)
- **Centralized AI observability**: Real-time usage tracking for 40+ key metrics and logs for every request
- **Governance** - Real-time spend tracking, set budget limits and RBAC in your LibreChat setup
- **Security Guardrails** - PII detection, content filtering, and compliance controls

This guide will walk you through integrating Portkey with LibreChat and setting up essential enterprise features including usage tracking, access controls, and budget management.

<Note>
  If you are an enterprise looking to use LibreChat in your organisation, [check out this section](#3-set-up-enterprise-governance-for-librechat).
</Note>

# 1. Setting up Portkey
Portkey allows you to use 1600+ LLMs with your LibreChat setup, with minimal configuration required. Let's set up the core components in Portkey that you'll need for integration.

<Steps>
<Step title="Create an Integration">
Navigate to the **Integrations** section in your Portkey dashboard. This is where you'll connect your LLM providers.

1. Find your preferred provider (e.g., OpenAI, Anthropic, etc.)
2. Click **Connect** on the provider card
3. In the "Create New Integration" window:
   - Enter a **Name** for reference
   - Add a **Short Description** (optional)
   - Enter a **Slug** for the integration
   - Choose between Public or Private Endpoint
   - Enter your **API Key** for the provider
4. Click **Next Step**

<Frame>
<img src="/images/integrations/create-integration.png" width="500"/>
</Frame>

<Note>
If this is your first time using Portkey, you'll see workspace provisioning options. You can select the "Shared Team Workspace" or create your own.
</Note>
</Step>

<Step title="Configure Models">
After creating the integration, you'll be prompted to configure model provisioning:

1. You can enable the toggle for **"Automatically enable new models from this provider"** to have all models available by default
2. Click **Next Step** to complete the integration

<Frame>
<img src="/images/integrations/model-provisioning.png" width="500"/>
</Frame>


</Step>


<Step title="Copy the Provider Slug">
Once your Integration is creted:

1. Navigate to the **AI Providers** tab in Model Catalog
2. Find your newly created provider
3. Copy the **slug** (e.g., `sadgas-39a139`)

<Frame>
<img src="/images/integrations/model-catalog.png" width="500"/>
</Frame>

<Note>
Save this slug - you'll use it in your LibreChat configuration just like how default configs were used before.
</Note>
</Step>

<Step title="Create Default Config">
Create a config to use your provider:

1. Go to [Configs](https://app.portkey.ai/configs) in Portkey dashboard
2. Create new config with:
    ```json
    {
        "virtual_key": "YOUR_PROVIDER_SLUG",
        "override_params": {
          "model": "gpt-4o" // Your preferred model name
        }
    }
    ```
3. Save and note the Config ID for the next step

<Frame>
<img src="/images/integrations/config.png" width="500"/>
</Frame>
</Step>

<Step title="Configure Portkey API Key">
Finally, create a Portkey API key:

1. Go to [API Keys](https://app.portkey.ai/api-keys) in Portkey
2. Create new API key
3. Select your config from Step 5
4. Generate and save your API key

<Frame>
<img src="/images/integrations/api-key.png" width="500"/>
</Frame>

<Note>
Save your API key securely - you'll need it for LibreChat integration.
</Note>
</Step>
</Steps>

## 2. Integrate Portkey with LibreChat

**Create the `docker-compose-override.yaml` file**

Create this file [following the instructions here](https://www.librechat.ai/docs/quick_start/custom_endpoints).
This file will point to the `librechat.yaml` file where we will configure our Portkey settings (in Step 3).

```yaml docker-compose.override.yml
services:
  api:
    volumes:
    - type: bind
      source: ./librechat.yaml
      target: /app/librechat.yaml
```

**Configure the `.env` file**

Edit your existing `.env` file at the project root (if the file does not exist, copy the `.env.example` file and rename to `.env`). We will add:

```env .env
PORTKEY_API_KEY=YOUR_PORTKEY_API_KEY
PORTKEY_BASE_URL=https://api.portkey.ai/v1
```

**Edit the `librechat.yaml` file**

Edit this file [following the instructions here](https://www.librechat.ai/docs/quick_start/custom_endpoints).
Here, you can either pass your **Config** (containing provider/model configurations) or use the provider **slug** directly.

<Note>
    LibreChat requires that the API key field is present. Since we don't need it for the Portkey integration, we can pass a dummy string for it.
</Note>
<CodeGroup>

```yaml librechat.yaml with Portkey Config
version: 1.1.4
cache: true
endpoints:
  custom:
    - name: "Portkey"
      apiKey: "dummy"
      baseURL: ${PORTKEY_GATEWAY_URL}
      headers:
        x-portkey-api-key: "${PORTKEY_API_KEY}"
        x-portkey-config: "pc-libre-xxx"
      models:
        default: ["llama-3.2"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      summarize: false
      summaryModel: "current_model"
      forcePrompt: false
      modelDisplayLabel: "Portkey:Llama"
```

```yaml librechat.yaml with Provider Slug
version: 1.1.4
cache: true
endpoints:
  custom:
    - name: "Portkey"
      apiKey: "dummy"
      baseURL: ${PORTKEY_GATEWAY_URL}
      headers:
        x-portkey-api-key: "${PORTKEY_API_KEY}"
        x-portkey-provider: "YOUR_PROVIDER_SLUG"
      models:
        default: ["gpt-4o-mini"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      summarize: false
      summaryModel: "current_model"
      forcePrompt: false
      modelDisplayLabel: "Portkey:OpenAI"
```
</CodeGroup>

<Note>
If you're a system admin, and you're looking to track the costs/user on a centralized instance of LibreChat, here's [a community guide by Tim Manik](https://github.com/timmanik/librechat-for-portkey).
</Note>

# 3. Set Up Enterprise Governance for LibreChat

**Why Enterprise Governance?**
If you are using LibreChat inside your orgnaization, you need to consider several governance aspects:
- **Cost Management**: Controlling and tracking AI spending across teams
- **Access Control**: Managing which teams can use specific models
- **Usage Analytics**: Understanding how AI is being used across the organization
- **Security & Compliance**: Maintaining enterprise security standards
- **Reliability**: Ensuring consistent service across all users

Portkey adds a comprehensive governance layer to address these enterprise
