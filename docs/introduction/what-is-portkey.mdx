---
title: "What is Portkey?"
description: Teams use Portkey to improve the cost, performance, and accuracy of their Gen AI apps.
---


It takes 2 mins to integrate and with that, it starts monitoring all of your LLM requests and makes your app resilient, secure, performant, and more accurate at the same time.

Here's a product walkthrough (3 mins):

<iframe width="100%" height="400px" src="https://www.youtube.com/embed/9aO340Hew2I?si=K988Sxs_A1qJg2ag" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Integrate in 3 Lines of Code

<CodeGroup>

```Python OpenAI Python
# pip install portkey-ai

from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

client = OpenAI(
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(provider="openai", api_key="PORTKEY_API_KEY")
)

chat_complete = client.chat.completions.create(
    model="o1-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
)

print(chat_complete.choices[0].message.content)
```

```js OpenAI Node
// npm i portkey-ai

import OpenAI from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai'

const openai = new OpenAI({
  baseURL: PORTKEY_GATEWAY_URL,
  defaultHeaders: createHeaders({provider: "openai", apiKey: "PORTKEY_API_KEY"})
});

async function main() {
  const chatCompletion = await openai.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'o1-mini',
  });

  console.log(chatCompletion.choices);
}

main();
```
</CodeGroup>
<CardGroup cols={2}>
  <Card title="Quickstart" icon="rocket" iconType="duotone" href="/docs/welcome/make-your-first-request">
    Setting up Portkey takes less than 2 minutes.
  </Card>
  <Card title="Integrations" icon="link" iconType="duotone" href="/docs/integrations/llms/openai">
    Find the best integration for you with 200+ models across LLM providers and multiple frameworks.
  </Card>
  <Card title="Product Features" icon="star" iconType="duotone" href="/docs/product/observability">
    Jump to the product section to learn more about the Portkey modules and the use cases they solve.
  </Card>
  <Card title="API Reference" icon="square-terminal" iconType="duotone" href="/docs/api-reference/authentication">
    Head to the API reference and code samples for all Portkey functionality available through REST APIs and SDKs.
  </Card>
</CardGroup>

<Check>
  While you're here, why not [give us a star](https://git.new/ai-gateway-docs)? It helps us a lot!
</Check>

 ### Languages Supported

| Language   | Supported Library                                                                                                               |
| ---------- | ------------------------------------------------------------------------------------------------------------------------------- |
| Javascript | [portkey-node-sdk](https://github.com/Portkey-AI/portkey-node-sdk)<br/> [openai-node](https://github.com/openai/openai-node)         |
| Python     | [portkey-python-sdk](https://github.com/Portkey-AI/portkey-python-sdk)<br/> [openai-python](https://github.com/openai/openai-python) |
| Go         | [go-openai](https://github.com/sashabaranov/go-openai)                                                                          |
| Java       | [openai-java](https://github.com/TheoKanning/openai-java)                                                                       |
| Rust       | [async-openai](https://github.com/64bit/async-openai)                                                                           |
| Ruby       | [ruby-openai](https://github.com/alexrudall/ruby-openai)                                                                        |

### AI Providers Supported

Portkey is multimodal by default - along with chat and text models, we also support audio, vision, and image generation models.

| AI Provider                                                             | Status                    |
| ----------------------------------------------------------------------- | ------------------------- |
| [OpenAI](/docs/integrations/llms/openai)                           | `fully supported` `public`     |
| [Anthropic](/docs/integrations/llms/anthropic)                     | `fully supported` `public`     |
| [Azure OpenAI](/docs/integrations/llms/azure-openai)               | `fully supported` `public`     |
| [Cohere](/docs/integrations/llms/cohere)                           | `fully supported` `public`     |
| [Anyscale](/docs/integrations/llms/anyscale-llama2-mistral-zephyr) | `fully supported` `public`     |
| [Google Palm](/docs/integrations/llms/google-palm)                 | `fully supported` `public`     |
| [Google Gemini](/docs/integrations/llms/gemini)                    | `fully supported` `public`     |
| [Together AI](/docs/integrations/llms/together-ai)                 | `fully supported` `public`     |
| [Perplexity](/docs/integrations/llms/perplexity-ai)                | `fully supported` `public`     |
| [Mistral](/docs/integrations/llms/mistral-ai)                      | `fully supported` `public`     |
| [Stability](/docs/integrations/llms/stability-ai)                  | `fully supported` `public`     |
| [Nomic](/docs/integrations/llms/nomic)                             | `fully supported` `public`     |
| AI21                                                                    | `fully supported` `public`     |
| [AWS Bedrock](/docs/integrations/llms/aws-bedrock)                 | `fully supported` `public`     |
| [Ollama](/docs/integrations/llms/ollama)                           | `fully supported` `public`     |
| AzureML                                                                 | `partially supported`       |
| [BYOLLM](/docs/integrations/llms/byollm)                           | `fully supported` `public`     |
| [Jina AI](/docs/integrations/llms/jina-ai)                         | `fully supported` `public`     |
| [Fireworks AI](/docs/integrations/llms/fireworks)                  | `fully supported` `public`     |
| [LocalAI](/docs/integrations/llms/local-ai)                        | `partially supported` `public` |
| [Predibase](/docs/integrations/llms/predibase)                     | `fully supported` `public`     |
| [ZhipuAI](/docs/integrations/llms/zhipu) (ChatGLM)                 | `fully supported` `public`     |
| [Deepinfra](/docs/integrations/llms/deepinfra)                     | `fully supported` `public`     |

[View all the supported integration guides](/docs/welcome/supported-llms).

### Frameworks Supported

| Framework                                                          | Status                 |
| ------------------------------------------------------------------ | ---------------------- |
| [Langchain](/docs/integrations/libraries/langchain-python)    | `native` `python` `typescript` |
| [Llamaindex](/docs/integrations/libraries/llama-index-python) | `native` `python` `typescript` |
| [Autogen](/docs/integrations/libraries/autogen)               | `native` `python`            |
| [Vercel](/docs/integrations/libraries/vercel)                 | `native` `typescript`       |
| [Instructor](/docs/integrations/libraries/instructor)         | `native` `python` `typescript` |
| [Promptfoo](/docs/integrations/libraries/promptfoo)           | `native` `typescript`       |
| [CrewAI](https://git.new/CrewAI-Portkey)                           | `native` `python`            |
