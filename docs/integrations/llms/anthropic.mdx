---
title: "Anthropic"
---

Portkey provides a robust and secure gateway to facilitate the integration of various Large Language Models (LLMs) into your applications, including [Anthropic's Claude APIs](https://docs.anthropic.com/claude/reference/getting-started-with-the-api).

With Portkey, you can take advantage of features like fast AI gateway access, observability, prompt management, and more, all while ensuring the secure management of your LLM API keys through a [virtual key](/docs/product/ai-gateway/virtual-keys) system.
<Note>Provider Slug. **`anthropic`**</Note>


## Portkey SDK Integration with Anthropic

Portkey provides a consistent API to interact with models from various providers. To integrate Anthropic with Portkey:

### 1\. Install the Portkey SDK

Add the Portkey SDK to your application to interact with Anthropic's API through Portkey's gateway.

<Tabs>
    <Tab title="NodeJS">
        ```
        npm install --save portkey-ai
        ```
    </Tab>
    <Tab title="Python">
        ```
        pip install portkey-ai
        ```
    </Tab>
  </Tabs>




### 2\. Initialize Portkey with the Virtual Key

To use Anthropic with Portkey, [get your Anthropic API key from here](https://console.anthropic.com/settings/keys), then add it to Portkey to create your Anthropic virtual key.

<Tabs>
    <Tab title="NodeJS SDK">

```
import Portkey from 'portkey-ai'


const portkey = new Portkey({

    apiKey: "PORTKEY_API_KEY", // defaults to process.env["PORTKEY_API_KEY"]

    virtualKey: "VIRTUAL_KEY" // Your Anthropic Virtual Key

})
```

    </Tab>
    <Tab title="Python SDK">

```
from portkey_ai import Portkey

portkey = Portkey(

    api_key="PORTKEY_API_KEY",  # Replace with your Portkey API key

    virtual_key="VIRTUAL_KEY"   # Replace with your virtual key for Anthropic

)
```
    </Tab>
  <Tab title="OpenAI Python SDK">

```
from openai import OpenAI

from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

client = OpenAI(

    api_key="ANTHROPIC_API_KEY",

    base_url=PORTKEY_GATEWAY_URL,

    default_headers=createHeaders(

        api_key="PORTKEY_API_KEY",

        provider="anthropic"

    )

)
```

    </Tab>
    <Tab title="OpenAI Node SDK">

```
import OpenAI from "openai";

import { PORTKEY_GATEWAY_URL, createHeaders } from "portkey-ai";

const client = new OpenAI({

  apiKey: "ANTHROPIC_API_KEY",

  baseURL: PORTKEY_GATEWAY_URL,

  defaultHeaders: createHeaders({

    provider: "anthropic",

    apiKey: "PORTKEY_API_KEY",

  }),

});
```
    </Tab>
  </Tabs>



### 3\. Invoke Chat Completions with Anthropic

Use the Portkey instance to send requests to Anthropic. You can also override the virtual key directly in the API call if needed.


<Tabs>
    <Tab title="NodeJS SDK">

```
const chatCompletion = await portkey.chat.completions.create({

    messages: [{ role: 'user', content: 'Say this is a test' }],

    model: 'claude-3-opus-20240229',

    max_tokens: 250 // Required field for Anthropic

});

console.log(chatCompletion.choices[0].message.content);
```

    </Tab>
    <Tab title="Python SDK">

```
chat_completion = portkey.chat.completions.create(

    messages= [{ "role": 'user', "content": 'Say this is a test' }],

    model= 'claude-3-opus-20240229',

    max_tokens=250 # Required field for Anthropic

)


print(chat_completion.choices[0].message.content)
```

    </Tab>
  <Tab title="OpenAI Python SDK">

```
chat_completion = client.chat.completions.create(

    messages = [{ "role": 'user', "content": 'Say this is a test' }],

    model = 'claude-3-opus-20240229',

    max_tokens = 250

)

print(chat_completion.choices[0].message.content)
```

    </Tab>
    <Tab title="OpenAI Node SDK">

```
async function main() {

    const chatCompletion = await client.chat.completions.create({

        model: "claude-3-opus-20240229",

        max_tokens: 1024,

        messages: [{ role: "user", content: "Hello, Claude" }],

    });

    console.log(chatCompletion.choices[0].message.content);

}

main();
```
    </Tab>
  </Tabs>


## How to Use Anthropic System Prompt

With Portkey, we make Anthropic models interoperable with the OpenAI schema and SDK methods. So, instead of passing the `system` prompt separately, you can pass it as part of the `messages` body, similar to OpenAI:

<Tabs>
    <Tab title="NodeJS">

```
const chatCompletion = await portkey.chat.completions.create({

    messages: [

        { role: 'system', content: 'Your system prompt' },

        { role: 'user', content: 'Say this is a test' }

    ],

    model: 'claude-3-opus-20240229',

    max_tokens: 250

});

console.log(chatCompletion.choices);
```

    </Tab>
    <Tab title="Python">

```
completion = portkey.chat.completions.create(

    messages= [

        { "role": 'system', "content": 'Your system prompt' },

        { "role": 'user', "content": 'Say this is a test' }

    ],

    model= 'claude-3-opus-20240229',

    max_tokens=250 # Required field for Anthropic

)


print(completion.choices)
```

    </Tab>

  </Tabs>


For more, check out the [chat completions](/docs/provider-endpoints/chat) and [completions](/docs/provider-endpoints/completions) API reference docs.Using Anthropic Vision Models

Portkey's multimodal Gateway fully supports Anthropic's vision models `claude-3-sonnet`, `claude-3-haiku`, `claude-3-opus`, and the newest `claude-3.5-sonnet`.

For more info, check out this guide:

[Vision](/docs/product/ai-gateway/multimodal-capabilities/vision)

## Managing Anthropic Prompts

You can manage all prompts to Anthropic in the [Prompt Library](/docs/product/prompt-library). All the current models of Anthropic are supported and you can easily start testing different prompts.

Once you're ready with your prompt, you can use the `portkey.prompts.completions.create` interface to use the prompt in your application.

## Next Steps

The complete list of features supported in the SDK are available on the link below.
<Info>[SDK](/docs/api-reference/portkey-sdk-client)</Info>


You'll find more information in the relevant sections:

1. [Add metadata to your requests](/docs/product/observability/metadata)
2. [Add gateway configs to your Anthropic requests](/docs/product/ai-gateway/configs)
3. [Tracing Anthropic requests](/docs/product/observability/traces)
4. [Setup a fallback from OpenAI to Anthropic's Claude APIs](/docs/product/ai-gateway/fallbacks)
