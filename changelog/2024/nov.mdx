---
title: "November"
---

**Portkey in November ❄️**

We won the NetApp Excellerator Award, launched [prompt.new](https://prompt.new/) for faster development, added folder organization and AI suggestions for prompt templates, introduced multi-workspace analytics. Plus, there's now support for OpenAI's Realtime API and much more. Let's dive in!

### Summary

| Area | Key Updates |
| :-- | :-- |
| Platform | • See multi-workspace analytics & logs on a single dashboard<br/>• Support for Realtime API across OpenAI and Azure OpenAI<br/>• More granular security & access control settings<br/>• Organize your prompts in folders |
| Integrations | • Route to AWS Sagemaker models through Portkey<br/>• Support for xAI provider and Llama 3.3 & Gemini 2.0 Flash models<br/>• New `strictOpenAiCompliance` flag on the Gateway |
| Enterprise | • Support for AWS STS with IMDS/IRSA auth<br/>• Support for Azure Entra (formerly Active Directory) to manage Azure auth<br/>• Set budget limits with periodic resets<br/>• Support for any S3-compatible store for logging |
| Community | • Won NetApp's Best Growth Strategy Award<br/>• Hosted first Practitioners Dinner in Singapore<br/>• Weekly AI Engineering Office Hours |


## Platform

#### Prompt Management
- Type [prompt.new](https://prompt.new) in your browser to spin up a new prompt playground! [Try it now →](https://prompt.new)
- Organize your prompt templates with folders and subfolders:
<Frame><iframe width="700" height="250" src="https://www.youtube.com/embed/Edn4UBkVZZk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe></Frame>
- Get tailored AI suggestions to improve your prompts - right inside the playground:
<Frame><iframe width="700" height="250" src="https://www.youtube.com/embed/1oU1oY0q9Ok" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe></Frame>
- Add version tags like `staging`, `production` to any prompt version to track changes, and call them directly:
<CodeGroup>
    ```ts @staging {2}
    const promptCompletion = portkey.prompts.completions.create({
        promptID: "pp-article-xx@staging",
        variables: {"":""}
    })
    ```
    ```ts @dev {2}
    const promptCompletion = portkey.prompts.completions.create({
        promptID: "pp-article-xx@dev",
        variables: {"":""}
    })
    ```
    ```ts @prod {2}
    const promptCompletion = portkey.prompts.completions.create({
        promptID: "pp-article-xx@prod",
        variables: {"":""}
    })
    ```
</CodeGroup>
- Each response inside the playground now gives metrics to monitor LLM throughput and latency
<Frame><img width="450" src="/images/changelog/prompt-metrics.png" /></Frame>

#### Analytics
- Track token distribution across both your requests & responses
<Frame><img width="150" src="/images/changelog/tokens-request-response.png" /></Frame>
- You can now filter logs and analytics with specific Portkey API keys. This is useful if you are tying a particular key to an internal user and want to see their usage!
- Owners can now see combined analytics & logs across all workspaces
<Frame><img width="600" src="/images/changelog/multi-workspace.gif" /></Frame>
- Dynamic usage and rate limits on API and Virtual keys. [Docs →](/product/ai-gateway/virtual-keys/budget-limits)

#### Enterprise
- Expanded AWS authentication options, for adding your Bedrock models or Sagemaker deployments:
  - IMDS-based auth (recommended for AWS environments)
  - IRSA-based auth for Kubernetes workloads
  - Role-based auth for non-AWS environments
  - STS integration with assumed roles
- Also expanded the Azure Integration:
  - Azure Entra (formerly Active Directory)
  - Managed identity support
- Granular access permissions for API Keys and Virtual Keys across your organization
<Frame><img width="450" src="/images/changelog/security-settings.png" /></Frame>

#### More
- Added the `strictOpenAiCompliance` flag for supporting provider-specific parameters. [Docs →](/product/ai-gateway/strict-open-ai-compliance)
- The [virtual key API](/api-reference/admin-api/control-plane/virtual-keys/create-virtual-key) now supports adding direct Azure deployment configuration


## Integrations

#### Providers
<CardGroup cols={2}>
<Card title="AWS Sagemaker" href="/integrations/llms/aws-sagemaker">
Add your Sagemaker deployments to Portkey easily
</Card>
<Card title="xAI" href="/integrations/llms/x-ai">
Call Grok models through Portkey!
</Card>
</CardGroup>

#### Libraries
<CardGroup cols={2}>
<Card title="OpenAI Swarm" href="/integrations/agents/openai-swarm">
Complete observability for Swarm agents
</Card>
<Card title="Supabase" href="/docs/integrations/libraries/supabase">
Add LLM features to your Supabase apps
</Card>
</CardGroup>

#### Guardrails
<CardGroup cols={2}>
<Card title="Pangea" href="/product/guardrails/pangea">
Enhanced security with PII detection and content moderation
</Card>
</CardGroup>

## Resources

#### Technical Guides
Essential reading for your AI infrastructure:
- [What is an LLM Gateway?](https://portkey.ai/blog/what-is-an-llm-gateway/): Complete introduction
- [O1 Models Analysis](https://portkey.ai/blog/openai-o1-model-card-analysis/): Understanding OpenAI's latest
- [LLM Gateway Guide](https://portkey.ai/blog/build-vs-buy-llm-gateways/): Making infrastructure choices
- [UI Comparison](https://portkey.ai/blog/librechat-vs-openwebui/): LibreChat vs OpenWebUI
- [AI vs API Gateway](https://portkey.ai/blog/ai-gateway-vs-api-gateway/): Key differences
- [GenAI Cost Control](https://portkey.ai/blog/finops-to-optimize-genai-costs/): Optimization strategies

#### Community
<CardGroup cols={2}>
<Card title="Our Scaling Story" href="https://www.youtube.com/watch?v=9VbjUBze9Y0">
Building our billion-request architecture
</Card>
<Card title="Office Hours" href="/changelog/office-hour">
Join our Friday technical discussions
</Card>
</CardGroup>

## Improvements

#### Providers
- Gemini: Enhanced message and media handling
- Bedrock: Improved message formatting
- Vertex AI: Added Zod validation

#### SDK
- Stream support for assistant threads
- Enhanced Pydantic compatibility
- Fixed semantic cache behavior
- Resolved Python Httpx proxy issues

---

## Support

<CardGroup cols={2}>
<Card title="Need Help?" icon="bug" href="https://github.com/Portkey-AI/gateway/issues">
Open an issue on GitHub
</Card>
<Card title="Join Us" icon="discord" href="https://portkey.wiki/community">
Get support in our Discord
</Card>
</CardGroup>

Special thanks to [harupy](https://github.com/harupy) and [Ignacio Gleser](https://www.linkedin.com/in/ignacio-gleser-3499b33a/) for their contributions!
