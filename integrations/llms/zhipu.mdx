---
title: "ZhipuAI / ChatGLM / BigModel"
---

[ZhipuAI](https://open.bigmodel.cn/) has developed the GLM series of open source LLMs that are some of the world's best performing and capable models today. Portkey provides a robust and secure gateway to seamlessly integrate these LLMs into your applications in the familiar OpenAI spec with just 2 LOC change!

With Portkey, you can leverage powerful features like fast AI gateway, caching, observability, prompt management, and more, while securely managing your LLM API keys through a virtual key system.
<Note>
Provider Slug. `zhipu`
</Note>
## Portkey SDK Integration with ZhipuAI

### 1\. Install the Portkey SDK

Install the Portkey SDK in your project using npm or pip:

<Tabs>
  <Tab title="NodeJS">
    ```sh
    npm install --save portkey-ai
    ```
  </Tab>
  <Tab title="Python">
```sh
pip install portkey-ai
```

  </Tab>

</Tabs>


### 2\. Initialize Portkey with the Virtual Key

To use ZhipuAI / ChatGLM / BigModel with Portkey, [get your API key from here](https://bigmodel.cn/usercenter/apikeys), then add it to Portkey to create the virtual key.
<Tabs>
  <Tab title="NodeJS SDK">
    ```js
    import Portkey from 'portkey-ai'

    const portkey = new Portkey({
        apiKey: "PORTKEY_API_KEY", // defaults to process.env["PORTKEY_API_KEY"]
        provider:"@PROVIDER" // Your ZhipuAI Virtual Key
    })
    ```
  </Tab>
  <Tab title="Python SDK">
```python
from portkey_ai import Portkey

portkey = Portkey(
    api_key="PORTKEY_API_KEY",  # Replace with your Portkey API key
    provider="@PROVIDER"   # Replace with your virtual key for ZhipuAI
)
```
  </Tab>

  <Tab title="OpenAI Node SDK">
```js
import OpenAI from "openai";
import { PORTKEY_GATEWAY_URL, createHeaders } from "portkey-ai";

const portkey = new OpenAI({
  baseURL: PORTKEY_GATEWAY_URL,
  defaultHeaders: createHeaders({
    apiKey: "PORTKEY_API_KEY",
    provider:"@ZHIPUAI_PROVIDER",
  }),
});
```

  </Tab>
  <Tab title="OpenAI Python SDK">
```python
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

portkey = OpenAI(
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        api_key="PORTKEY_API_KEY",
        provider="@ZHIPUAI_PROVIDER"
    )
)
```
  </Tab>
</Tabs>



### 3\. Invoke Chat Completions
<Tabs>
  <Tab title="Portkey OR OpenAI NodeJS SDK">
    ```js
    const chatCompletion = await portkey.chat.completions.create({
        messages: [{ role: 'user', content: 'Who are you?' }],
        model: 'glm-4'
    });

    console.log(chatCompletion.choices);
    ```

    > I am an AI assistant named ZhiPuQingYanï¼ˆæ™ºè°±æ¸…è¨€ï¼‰, you can call me XiaozhiðŸ¤–

  </Tab>
  <Tab title="Portkey OR OpenAI Python SDK">
```python
completion = portkey.chat.completions.create(
    messages= [{ "role": 'user', "content": 'Say this is a test' }],
    model= 'glm-4'
)

print(completion)
```

> I am an AI assistant named ZhiPuQingYanï¼ˆæ™ºè°±æ¸…è¨€ï¼‰, you can call me XiaozhiðŸ¤–

  </Tab>
<Tab title="cURL">
  ```sh
  curl https://api.portkey.ai/v1/chat/completions \
    -H "Content-Type: application/json" \
    -H "x-portkey-api-key: $PORTKEY_API_KEY" \
    -H "x-portkey-provider: $ZHIPUAI_PROVIDER" \
    -d '{
      "messages": [{"role": "user","content": "Hello!"}],
      "model": "glm-4",
    }'
  ```

  > I am an AI assistant named ZhiPuQingYanï¼ˆæ™ºè°±æ¸…è¨€ï¼‰, you can call me XiaozhiðŸ¤–

  </Tab>

</Tabs>

---

## Next Steps

The complete list of features supported in the SDK are available on the link below.
<Card title="SDK" href="/api-reference/portkey-sdk-client">
</Card>

You'll find more information in the relevant sections:

1. [Add metadata to your requests](/product/observability/metadata)
2. [Add gateway configs to your ZhipuAI requests](/product/ai-gateway/configs)
3. [Tracing ZhipuAI requests](/product/observability/traces)
4. [Setup a fallback from OpenAI to ZhipuAI](/product/ai-gateway/fallbacks)
