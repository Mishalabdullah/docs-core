---
title: Model Catalog
description: Explore and query every AI model available to your workspace, with instant code snippets for all supported providers.
---

The **Model Catalog** is the evolution of Virtual Keys, providing a centralized and powerful way to manage, discover, and use AI models within your workspace. It consists of two main sections: **AI Providers**, where you manage your connections, and **Models**, where you explore what you can use.

### **How it Works: Inheritance from the Organization**

The most significant change with the Model Catalog is the concept of inheritance. Think of it this way:

1.  Your **Organization Admin** creates a master **Integration** at the company level (e.g., for "Azure Production"). They add the credentials and can set default budgets, rate limits, and an allow-list of approved models for that integration.
2.  When they provision this integration to your workspace, a corresponding **AI Provider** is automatically created in your Model Catalog.
3.  This new AI Provider in your workspace *inherits* all the settings from the organization-level integration, including its credentials, model access, and spending limits.

This "create once, provision many" approach provides central governance while giving workspaces the flexibility they need.

---

### **The Model Catalog Experience by Role**

Your experience with the Model Catalog will differ based on your role within the Portkey organization.

#### **For Workspace Members (Developers): Discover and Build**

As a developer, your experience is simplified and streamlined. You primarily interact with the **Models** tab, which acts as your personal "Model Garden."

-   **Discover Models:** The "Models" tab is a complete gallery of every single model you have been given access to by your admins.
-   **Get Code Snippets:** Click on any model, and Portkey will generate the exact code snippet you need to start making calls, with the correct provider and model slugs already included.
-   **Simplified API Calls:** You can now call any model directly using the `model` parameter, formatted as `@{provider_slug}/{model_slug}`. This lets you switch between providers and models on the fly with a single Portkey API key.

```python
# Switch between a model on OpenAI and one on Bedrock seamlessly
client.chat.completions.create(
    model="@openai-prod/gpt-4o", 
    messages=[...]
)

client.chat.completions.create(
    model="@bedrock-us/claude-3-sonnet-v1",
    messages=[...]
)
```

#### **For Workspace Admins: Manage and Customize**

As a Workspace Admin, you have more control over the providers within your workspace via the **AI Providers** tab.

You will see a list of providers that have been inherited from the organization. From here, you have two primary options when you click **Create Provider**:

1.  **Inherit from an Org Integration:** You can create *additional* providers that are based on an existing org-level integration. This is useful for subdividing access within your team. For example, if your workspace has a $1000 budget on the main "Azure Prod" integration, you could create a new provider from it named "azure-prod-experimental" and give it a stricter $100 budget for a specific project.
2.  **Create a New Workspace-Exclusive Integration:** If your Org Admin has enabled the permission, you can create a brand new integration from scratch. This provider is exclusive to your workspace and functions just like the old Virtual Keys did.

#### **For Organization Admins: A View into Workspaces**

While Org Admins primarily work in the main **[Integrations](/product/integrations)** dashboard, the Model Catalog provides a crucial feedback loop:

When a Workspace Admin creates a new, workspace-exclusive integration (option #2 above), you gain full visibility. This new integration will automatically appear on your main Integrations page under the **"Workspace-Created"** tab, ensuring you always have a complete audit trail of all provider credentials being used across the organization.