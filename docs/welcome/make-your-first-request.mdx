---
title: "Make Your First Request"
description: "Integrate Portkey and analyze your first LLM call in 2 minutes!"
---

## 1\. Get your Portkey API Key

[Create](https://app.portkey.ai/signup) or [log in](https://app.portkey.ai/login) to your Portkey account. Grab your account's API key from the "Settings" page.

<Frame caption="Copy your Portkey account API key">
  <img src="/images/welcome/welcome-2.gif" alt="Copy your Portkey account API key" />
</Frame>

Based on your access level, you might see the relevant permissions on the API key modal - tick the ones you'd like, name your API key, and save it.

## 2\. Integrate Portkey

Portkey offers a variety of integration options, including SDKs, REST APIs, and native connections with platforms like OpenAI, Langchain, and LlamaIndex, among others.

### Through the OpenAI SDK

If you're using the **OpenAI SDK**, import the Portkey SDK and configure it within your OpenAI client object:

<Card title="OpenAI" href="/docs/integrations/llms/openai" />


### Portkey SDK

You can also use the **Portkey SDK / REST APIs** directly to make the chat completion calls. This is a more versatile way to make LLM calls across any provider:

<Card title="SDK" href="/docs/api-reference/portkey-sdk-client" />


Once, the integration is ready, you can view the requests reflect on your Portkey dashboard.

<Frame>
  <img src="https://docs.portkey.ai/~gitbook/image?url=https%3A%2F%2F2878743244-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252Fy3MCfQqftZOnHqSmVV5x%252Fuploads%252FzWw4VMOnC5rSBQpeJQOG%252Fanalytics_logs.gif%3Falt%3Dmedia%26token%3Daf8b4689-37d2-4298-ac9a-91c21f9cfc2b&width=400&dpr=2&quality=100&sign=edcf8ba2&sv=1"/>
</Frame>


### Other Integration Guides

<CardGroup cols={3}>
  <Card title="Azure OpenAI" href="/docs/integrations/llms/azure-openai" />
  <Card title="Anthropic" href="/docs/integrations/llms/anthropic" />
  <Card title="Langchain" href="/docs/integrations/libraries/langchain-python" />
  <Card title="LlamaIndex" href="/docs/integrations/libraries/llama-index-python" />
  <Card title="Ollama" href="https://github.com/Portkey-AI/docs/blob/v2/welcome/broken-reference/README.md" />
  <Card title="Others" href="/docs/provider-endpoints/gateway-for-other-apis" />
</CardGroup>

## 3\. Next Steps

Now that you're up and running with Portkey, you can dive into the various Portkey features to learn about all of the supported functionalities:

<CardGroup cols={3}>
  <Card title="Observability" href="/docs/product/observability/" />
  <Card title="AI Gateway" href="/docs/product/ai-gateway" />
  <Card title="Prompt Library" href="/docs/product/prompt-library" />
  <Card title="Autonomous Fine-Tuning" href="/docs/product/autonomous-fine-tuning" />
</CardGroup>

<Check>
While you're here, why not [give us a star](https://git.new/ai-gateway-docs)? It helps us a lot!
</Check>

## FAQs

### Will Portkey increase the latency of my API requests?

Portkey is hosted on edge workers throughout the world and our servers ensure the least latency roundtrips. Our benchmarks estimate a total latency addition between 20-40ms.

Our edge worker locations:

<Frame>
  <img src="/images/welcome/welcome-4.avif"  />
</Frame>


### Is my data secure?

Portkey is ISO:27001 and SOC 2 certified. We're also GDPR compliant. This is proof that we maintain the best practices involving security of our services, data storage and retrieval. All your data is encrypted in transit and at rest.

If you're still worried about your data passing through Portkey, we recommend one of the below options:

1. On request, we can enable a feature that does NOT store any of your request and response body objects in the Portkey datastores or our logs.
2. For enterprises, we offer managed hosting to deploy Portkey inside private clouds.

If you need to talk about these options, feel free to drop us a note on hello@portkey.ai

### Will Portkey scale if my app explodes?

Portkey has been tested to handle millions of requests per second. We serve over 10M requests everyday with a 99.99% uptime. We're built of top of scalable infrastructure and can handle huge loads without breaking a sweat.

[**View our Status Page**](https://status.portkey.ai)

### Does Portkey impose timeouts on requests?

We do not impose **any explicit timeout** for our free OR paid plans currently. In the past, we have had users experience timeouts from various other frameworks, but Portkey does not time out requests on our end.

### Do you support sign ups from non-google/gmail accounts?

Yes! We support registrations with Microsoft accounts - this is currently in beta. Please reach out on support@portkey.ai or [request on Discord](https://discord.gg/kXYKpPGasJ) for access to MS login.

### Where can I reach you?

We're available all the time on [Discord](https://discord.gg/DD7vgKK299), or on our support email - support@portkey.ai
